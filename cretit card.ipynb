{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb1f69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1162848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f80d307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cbeb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5127454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b0f1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "284802  0.943651  0.823731    0.77      0  \n",
       "284803  0.068472 -0.053527   24.79      0  \n",
       "284804  0.004455 -0.026561   67.88      0  \n",
       "284805  0.108821  0.104533   10.00      0  \n",
       "284806 -0.002415  0.013649  217.00      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f3a1f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a0e823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 31\n",
      "Number of rows: 284807\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of columns: {}\".format(data.shape[1]))\n",
    "print(\"Number of rows: {}\".format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37545cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "122bf50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98705471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8329fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "data['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "172671af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca58c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105f3180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c53180fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22a3990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a52908ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4ffa324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "094704da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eaab4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1)\n",
    "y=data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2909ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9080445",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fcfedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9539cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b888887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Logistic Regression===========\n",
      "\n",
      " Accuracy: 0.9991222218320986\n",
      " Precision: 0.8636363636363636\n",
      " Recall: 0.5816326530612245\n",
      " F1 Score: 0.6951219512195121\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56855     9]\n",
      " [   41    57]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.86      0.58      0.70        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.79      0.85     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Decision Tree Classifier===========\n",
      "\n",
      " Accuracy: 0.9991397773954567\n",
      " Precision: 0.7425742574257426\n",
      " Recall: 0.7653061224489796\n",
      " F1 Score: 0.7537688442211056\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56838    26]\n",
      " [   23    75]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.74      0.77      0.75        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.88      0.88     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Random Forest Classifier===========\n",
      "\n",
      " Accuracy: 0.9995435553526912\n",
      " Precision: 0.9615384615384616\n",
      " Recall: 0.7653061224489796\n",
      " F1 Score: 0.8522727272727273\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56861     3]\n",
      " [   23    75]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.96      0.77      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.88      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Support Vector Classifier===========\n",
      "\n",
      " Accuracy: 0.9994382219725431\n",
      " Precision: 0.8837209302325582\n",
      " Recall: 0.7755102040816326\n",
      " F1 Score: 0.826086956521739\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56854    10]\n",
      " [   22    76]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.88      0.78      0.83        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.89      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========K-Nearest Neighbors Classifier===========\n",
      "\n",
      " Accuracy: 0.9995259997893332\n",
      " Precision: 0.9382716049382716\n",
      " Recall: 0.7755102040816326\n",
      " F1 Score: 0.8491620111731844\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56859     5]\n",
      " [   22    76]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.94      0.78      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Gaussian Naive Bayes===========\n",
      "\n",
      " Accuracy: 0.9778624346055265\n",
      " Precision: 0.06113207547169811\n",
      " Recall: 0.826530612244898\n",
      " F1 Score: 0.11384399156711174\n",
      "\n",
      " Confusion Matrix:\n",
      "[[55620  1244]\n",
      " [   17    81]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56864\n",
      "           1       0.06      0.83      0.11        98\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.53      0.90      0.55     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n",
      "\n",
      "==========AdaBoost Classifier===========\n",
      "\n",
      " Accuracy: 0.9992977774656788\n",
      " Precision: 0.8372093023255814\n",
      " Recall: 0.7346938775510204\n",
      " F1 Score: 0.782608695652174\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56850    14]\n",
      " [   26    72]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.84      0.73      0.78        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.87      0.89     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Gradient Boosting Classifier===========\n",
      "\n",
      " Accuracy: 0.9989466661985184\n",
      " Precision: 0.7375\n",
      " Recall: 0.6020408163265306\n",
      " F1 Score: 0.6629213483146067\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56843    21]\n",
      " [   39    59]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.74      0.60      0.66        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.80      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Bagging Classifier===========\n",
      "\n",
      " Accuracy: 0.9995611109160493\n",
      " Precision: 0.9506172839506173\n",
      " Recall: 0.7857142857142857\n",
      " F1 Score: 0.8603351955307262\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56860     4]\n",
      " [   21    77]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.95      0.79      0.86        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Extra Trees Classifier===========\n",
      "\n",
      " Accuracy: 0.9995435553526912\n",
      " Precision: 0.95\n",
      " Recall: 0.7755102040816326\n",
      " F1 Score: 0.8539325842696629\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56860     4]\n",
      " [   22    76]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.95      0.78      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Stochastic Gradient Descent Classifier===========\n",
      "\n",
      " Accuracy: 0.9989817773252344\n",
      " Precision: 0.8125\n",
      " Recall: 0.5306122448979592\n",
      " F1 Score: 0.6419753086419753\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56852    12]\n",
      " [   46    52]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.81      0.53      0.64        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.77      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "==========Voting Classifier===========\n",
      "\n",
      " Accuracy: 0.9995259997893332\n",
      " Precision: 0.927710843373494\n",
      " Recall: 0.7857142857142857\n",
      " F1 Score: 0.850828729281768\n",
      "\n",
      " Confusion Matrix:\n",
      "[[56858     6]\n",
      " [   21    77]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.93      0.79      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"K-Nearest Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"Bagging Classifier\": BaggingClassifier(),\n",
    "    \"Extra Trees Classifier\": ExtraTreesClassifier(),\n",
    "    \"Stochastic Gradient Descent Classifier\": SGDClassifier(),\n",
    "    \"Voting Classifier\": VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression()),\n",
    "        ('dt', DecisionTreeClassifier()),\n",
    "        ('rf', RandomForestClassifier()),\n",
    "        ('svc', SVC()),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ], voting='hard')\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluation Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"\\n Accuracy: {accuracy}\")\n",
    "    print(f\" Precision: {precision}\")\n",
    "    print(f\" Recall: {recall}\")\n",
    "    print(f\" F1 Score: {f1}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\n Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\n Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4c6b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = data[data['Class']==0]\n",
    "fraud = data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "157c3db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "034e5998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61ddfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample = normal.sample(n=473)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "687796ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21579e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([normal_sample,fraud], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92dfe07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.315771</td>\n",
       "      <td>-0.032971</td>\n",
       "      <td>-1.089771</td>\n",
       "      <td>-0.557242</td>\n",
       "      <td>2.030119</td>\n",
       "      <td>3.268061</td>\n",
       "      <td>-0.535246</td>\n",
       "      <td>0.808299</td>\n",
       "      <td>-0.052702</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>-0.028612</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>0.041251</td>\n",
       "      <td>0.425457</td>\n",
       "      <td>1.245253</td>\n",
       "      <td>0.640342</td>\n",
       "      <td>-0.910242</td>\n",
       "      <td>-0.068737</td>\n",
       "      <td>0.255328</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.313423</td>\n",
       "      <td>-1.068834</td>\n",
       "      <td>0.103964</td>\n",
       "      <td>0.992116</td>\n",
       "      <td>0.369468</td>\n",
       "      <td>0.110394</td>\n",
       "      <td>-0.028266</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>-0.346073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.055364</td>\n",
       "      <td>-2.209773</td>\n",
       "      <td>0.742884</td>\n",
       "      <td>-1.148226</td>\n",
       "      <td>-2.424800</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-2.514556</td>\n",
       "      <td>0.438666</td>\n",
       "      <td>0.252089</td>\n",
       "      <td>1.300124</td>\n",
       "      <td>-0.362697</td>\n",
       "      <td>0.675321</td>\n",
       "      <td>0.997706</td>\n",
       "      <td>-1.826652</td>\n",
       "      <td>-2.655351</td>\n",
       "      <td>-0.606619</td>\n",
       "      <td>0.634896</td>\n",
       "      <td>0.662052</td>\n",
       "      <td>0.453341</td>\n",
       "      <td>-0.331223</td>\n",
       "      <td>-0.006937</td>\n",
       "      <td>0.863080</td>\n",
       "      <td>0.116879</td>\n",
       "      <td>-0.339508</td>\n",
       "      <td>-0.345829</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116789</td>\n",
       "      <td>-0.034098</td>\n",
       "      <td>-0.156524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.313940</td>\n",
       "      <td>0.685727</td>\n",
       "      <td>1.971718</td>\n",
       "      <td>-0.360972</td>\n",
       "      <td>-0.098111</td>\n",
       "      <td>-0.723852</td>\n",
       "      <td>0.578164</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.342708</td>\n",
       "      <td>-0.527251</td>\n",
       "      <td>-1.045297</td>\n",
       "      <td>-0.551028</td>\n",
       "      <td>-1.486262</td>\n",
       "      <td>-0.121128</td>\n",
       "      <td>-0.503199</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>-0.142089</td>\n",
       "      <td>-0.509159</td>\n",
       "      <td>-0.197421</td>\n",
       "      <td>-0.158264</td>\n",
       "      <td>-0.316265</td>\n",
       "      <td>-0.769208</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.367526</td>\n",
       "      <td>0.371286</td>\n",
       "      <td>0.213550</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.111196</td>\n",
       "      <td>-0.330680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.102748</td>\n",
       "      <td>-0.084781</td>\n",
       "      <td>-1.644359</td>\n",
       "      <td>0.079454</td>\n",
       "      <td>0.395719</td>\n",
       "      <td>-0.602038</td>\n",
       "      <td>0.106627</td>\n",
       "      <td>-0.211735</td>\n",
       "      <td>0.857887</td>\n",
       "      <td>-0.091910</td>\n",
       "      <td>-1.169126</td>\n",
       "      <td>-0.104172</td>\n",
       "      <td>-0.383665</td>\n",
       "      <td>0.556490</td>\n",
       "      <td>1.035875</td>\n",
       "      <td>-0.172516</td>\n",
       "      <td>-0.623029</td>\n",
       "      <td>0.228425</td>\n",
       "      <td>-0.088101</td>\n",
       "      <td>-0.251743</td>\n",
       "      <td>0.235796</td>\n",
       "      <td>0.811528</td>\n",
       "      <td>-0.027352</td>\n",
       "      <td>0.277517</td>\n",
       "      <td>0.378112</td>\n",
       "      <td>-0.420342</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>-0.052976</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157113</td>\n",
       "      <td>-2.209728</td>\n",
       "      <td>0.261917</td>\n",
       "      <td>-0.252468</td>\n",
       "      <td>-1.828196</td>\n",
       "      <td>-0.608249</td>\n",
       "      <td>0.106177</td>\n",
       "      <td>-0.154349</td>\n",
       "      <td>1.856645</td>\n",
       "      <td>-1.319762</td>\n",
       "      <td>-0.543270</td>\n",
       "      <td>0.504392</td>\n",
       "      <td>-0.349297</td>\n",
       "      <td>0.031819</td>\n",
       "      <td>1.401304</td>\n",
       "      <td>-0.364286</td>\n",
       "      <td>-0.113201</td>\n",
       "      <td>0.520209</td>\n",
       "      <td>0.294413</td>\n",
       "      <td>0.997918</td>\n",
       "      <td>0.473779</td>\n",
       "      <td>0.341013</td>\n",
       "      <td>-0.623436</td>\n",
       "      <td>0.452514</td>\n",
       "      <td>0.403059</td>\n",
       "      <td>-0.590010</td>\n",
       "      <td>-0.014561</td>\n",
       "      <td>0.130263</td>\n",
       "      <td>1.907289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.315771 -0.032971 -1.089771 -0.557242  2.030119  3.268061 -0.535246   \n",
       "1  2.055364 -2.209773  0.742884 -1.148226 -2.424800  1.020713 -2.514556   \n",
       "2 -1.313940  0.685727  1.971718 -0.360972 -0.098111 -0.723852  0.578164   \n",
       "3  2.102748 -0.084781 -1.644359  0.079454  0.395719 -0.602038  0.106627   \n",
       "4  0.157113 -2.209728  0.261917 -0.252468 -1.828196 -0.608249  0.106177   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.808299 -0.052702  0.001237 -0.028612  0.073649  0.041251  0.425457   \n",
       "1  0.438666  0.252089  1.300124 -0.362697  0.675321  0.997706 -1.826652   \n",
       "2  0.038198  0.342708 -0.527251 -1.045297 -0.551028 -1.486262 -0.121128   \n",
       "3 -0.211735  0.857887 -0.091910 -1.169126 -0.104172 -0.383665  0.556490   \n",
       "4 -0.154349  1.856645 -1.319762 -0.543270  0.504392 -0.349297  0.031819   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.245253  0.640342 -0.910242 -0.068737  0.255328  0.016565 -0.313423   \n",
       "1 -2.655351 -0.606619  0.634896  0.662052  0.453341 -0.331223 -0.006937   \n",
       "2 -0.503199  0.003163 -0.142089 -0.509159 -0.197421 -0.158264 -0.316265   \n",
       "3  1.035875 -0.172516 -0.623029  0.228425 -0.088101 -0.251743  0.235796   \n",
       "4  1.401304 -0.364286 -0.113201  0.520209  0.294413  0.997918  0.473779   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0 -1.068834  0.103964  0.992116  0.369468  0.110394 -0.028266  0.011803   \n",
       "1  0.863080  0.116879 -0.339508 -0.345829  0.023391  0.116789 -0.034098   \n",
       "2 -0.769208  0.006561  0.367526  0.371286  0.213550 -0.008363  0.111196   \n",
       "3  0.811528 -0.027352  0.277517  0.378112 -0.420342  0.002852 -0.052976   \n",
       "4  0.341013 -0.623436  0.452514  0.403059 -0.590010 -0.014561  0.130263   \n",
       "\n",
       "     Amount  Class  \n",
       "0 -0.346073      0  \n",
       "1 -0.156524      0  \n",
       "2 -0.330680      0  \n",
       "3 -0.349231      0  \n",
       "4  1.907289      0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "426f6796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1    492\n",
       "0    473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e058e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop('Class', axis = 1)\n",
    "y= new_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72efcbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5550e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Logistic Regression===========\n",
      "\n",
      " Accuaracy: 0.9222797927461139\n",
      "\n",
      " Precision: 0.9583333333333334\n",
      "\n",
      " Recall: 0.8932038834951457\n",
      "\n",
      " F1 Score: 0.9246231155778895\n",
      "\n",
      "==========Decision Tree Classifier===========\n",
      "\n",
      " Accuaracy: 0.8911917098445595\n",
      "\n",
      " Precision: 0.9270833333333334\n",
      "\n",
      " Recall: 0.8640776699029126\n",
      "\n",
      " F1 Score: 0.8944723618090452\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuaracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n F1 Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8501a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1)\n",
    "y= data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cadca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56776250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df1dce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\nitin\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Collecting imbalanced-learn\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/5a/fa/267de06c95210580f4b82b45cec1ce1e9ce1f21a01a684367db89e7da70d/imbalanced_learn-0.12.3-py3-none-any.whl.metadata\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 0.0/258.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/258.3 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 92.2/258.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 258.3/258.3 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "  Attempting uninstall: imbalanced-learn\n",
      "    Found existing installation: imbalanced-learn 0.10.1\n",
      "    Uninstalling imbalanced-learn-0.10.1:\n",
      "      Successfully uninstalled imbalanced-learn-0.10.1\n",
      "Successfully installed imbalanced-learn-0.12.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00e75c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\nitin\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75110b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c61d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = SMOTE().fit_resample(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7650d882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1    284315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e085369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ad5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b94c01cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Logistic Regression===========\n",
      "\n",
      " Accuaracy: 0.9716687476918207\n",
      "\n",
      " Precision: 0.9793472445157838\n",
      "\n",
      " Recall: 0.9637742207245156\n",
      "\n",
      " F1 Score: 0.971498328114219\n",
      "\n",
      "==========Decision Tree Classifier===========\n",
      "\n",
      " Accuaracy: 0.9984436276664966\n",
      "\n",
      " Precision: 0.9976170033817525\n",
      "\n",
      " Recall: 0.999280398764392\n",
      "\n",
      " F1 Score: 0.9984480082772892\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuaracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n F1 Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9783e96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be9f94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ba58c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credit_card_model.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dtc, \"credit_card_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ac6aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"credit_card_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f38621e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([[-1.3598071336738,-0.0727811733098497,2.53634673796914,1.37815522427443,-0.338320769942518,0.462387777762292,0.239598554061257,0.0986979012610507,0.363786969611213,0.0907941719789316,-0.551599533260813,-0.617800855762348,-0.991389847235408,-0.311169353699879,1.46817697209427,-0.470400525259478,0.207971241929242,0.0257905801985591,0.403992960255733,0.251412098239705,-0.018306777944153,0.277837575558899,-0.110473910188767,0.0669280749146731,0.128539358273528,0.0669280749146731,-0.189114843888824,0.133558376740387,-0.0210530534538215,149.62]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "081ea443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eebc436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transcation\n"
     ]
    }
   ],
   "source": [
    "if pred[0] == 0:\n",
    "    print(\"Normal Transcation\")\n",
    "else:\n",
    "    print(\"Fraud Transcation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718329ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
